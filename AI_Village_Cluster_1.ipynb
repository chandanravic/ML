{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONZloS8cW6ym3feQaHmmom",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandanravic/ML/blob/main/AI_Village_Cluster_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "load the pretrained model\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "-UYbLmAwxmhG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x5mM9J89mdpI"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "input_data = [0]\n",
        "\n",
        "def query(input_data):\n",
        "    response = requests.post('http://cluster1.advml.com/score', json={'data': input_data})\n",
        "    return response.json()\n",
        "\n",
        "#query(input_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "install packages"
      ],
      "metadata": {
        "id": "_D7RwpGmx96O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install skops\n",
        "!pip -q install scikit-learn==1.3.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z18aoghnnxU0",
        "outputId": "8cbf4c9b-bbd1-402a-c90f-9348ab60a355"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.7/120.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* import libraries\n",
        "\n",
        "* load the files, ML file and the dataset to pandas dataframe, sorting the id and reset the index\n",
        "\n",
        "* load the ML function pipe to predict the data, adding column pos_misclassified to check if prediction matches actual.\n",
        "and adding 1 to each row just for fun i guess."
      ],
      "metadata": {
        "id": "ewVGeb7EyBpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import skops.io as sio\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import itertools\n",
        "\n",
        "pipe = sio.load(\"/content/sample_data/census_model.skops\", trusted=True)\n",
        "data = pd.read_csv(\"/content/sample_data/census.csv\").sort_values('id').reset_index(drop=True)\n",
        "\n",
        "prediction = pipe.predict(data)\n",
        "data['pos_missclassified'] =  prediction != data.income#(prediction == '>50K') & (data.income == '<=50K')\n",
        "data['counter'] = 1"
      ],
      "metadata": {
        "id": "g_eUP4M8pF4R"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = [ 'workclass', 'education.num', 'marital.status', 'occupation',\n",
        "            'relationship', 'race', 'sex', 'native.country']\n",
        "\n",
        "\n",
        "\n",
        "all_missclassifications = []\n",
        "max_misclassifications = -1\n",
        "max_misclassified_cluster = None\n",
        "max_combination = None\n",
        "\n",
        "for r in range(1, len(features) + 1):\n",
        "    for subset in itertools.combinations(features, r):\n",
        "        subset = list(subset)\n",
        "\n",
        "        g = data.groupby(subset)[[ 'pos_missclassified',  'counter']].sum()\n",
        "        group = g['pos_missclassified']/g['counter']\n",
        "        grouped = group[g['counter'] >= 162]\n",
        "        if len(grouped) == 0:\n",
        "            continue\n",
        "\n",
        "        current_max_misclassifications = grouped.max()\n",
        "        all_missclassifications.append(grouped.values)\n",
        "        if current_max_misclassifications > max_misclassifications:\n",
        "            max_misclassifications = current_max_misclassifications\n",
        "            max_misclassified_cluster = grouped.idxmax()\n",
        "            max_combination = subset\n",
        "\n",
        "            max_misclassified_cluster\n",
        "\n",
        "\n",
        "max_misclassified_cluster\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Pj4lLesV6rC",
        "outputId": "8ca69947-e890-45e1-f975-bba4a5b26d2d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Tech-support', 'Female')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}